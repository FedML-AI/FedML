common_args:
  training_type: "cross_silo"
  random_seed: 0
  scenario: "horizontal"
  using_mlops: false
  config_version: release
  name: "exp"
  project: "runs/train"
  exist_ok: false

data_args:
  dataset: "wikiner"
  data_file_path: ~/fednlp_data/data_files/wikiner_data.h5
  partition_file_path: ~/fednlp_data/partition_files/wikiner_partition.h5
  partition_method: "uniform"
  reprocess_input_data: false
  global_model_file_path: "/home/ubuntu/FedML/python/app/model_cache_dir/"
  model_file_cache_folder: "/home/ubuntu/FedML/python/app/model_cache_dir/global_model.pt"

model_args:
  model_type: "bert"
  model_class: "transformer"
  model: "bert-base-uncased"
  do_lower_case: true
  formulation: "seq_tagging"

environment_args:
  bootstrap: config/bootstrap.sh

train_args:
  federated_optimizer: "FedAvg"
  client_id_list:
  client_num_in_total: 100
  client_num_per_round: 1
  comm_round: 50
  epochs: 1
  batch_size: 16
  eval_batch_size: 8
  max_seq_length: 128
  fp16: false
  output_dir: "~/output_dir"
  client_optimizer: AdamW
  server_optimizer: sgd
  server_momentum: 0.9
  server_lr: 0.1
  learning_rate: 0.001
  weight_decay: 0.001
  gradient_accumulation_steps: 1
  clip_grad_norm: true
  fedprox_mu: 1
  evaluate_during_training: false
  evaluate_during_training_steps: 10
  freeze_layers: ''
  is_debug_mode: false
  momentum: 0.9
  max_grad_norm: 1
  ci: 0

validation_args:
  frequency_of_the_test: 5

device_args:
  worker_num: 1
  using_gpu: false
  gpu_mapping_file: config/gpu_mapping.yaml
  gpu_mapping_key: mapping_fednlp_sp

comm_args:
  backend: "MQTT_S3"
  mqtt_config_path: config/mqtt_config.yaml
  s3_config_path: config/s3_config.yaml


tracking_args:
   # When running on MLOps platform(open.fedml.ai), the default log path is at ~/fedml-client/fedml/logs/ and ~/fedml-server/fedml/logs/
  enable_wandb: false
  wandb_key: ee0b5f53d949c84cee7decbe7a629e63fb2f8408
  wandb_project: fedml
  wandb_name: fedml_torch_fedavg_mnist_lr
